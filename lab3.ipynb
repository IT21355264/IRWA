{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wl79-TWys5NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b858e2-aef2-4eee-80ce-e99ec43deb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab  import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/IRWA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJ2bHEusi1x",
        "outputId": "80160d0f-bbbd-42e2-c88b-aabc67dac964"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "\n",
        "\n",
        "text=\"september is the best month\"\n",
        "tokenized=word_tokenize(text)\n",
        "\n",
        "ng=ngrams(tokenized,3)\n",
        "\n",
        "y=[' '.join(x) for x in ng]\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5HQfa4Jdwoj",
        "outputId": "b934d2b2-c376-4d3a-bef6-fb299cf9d93a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['september is the', 'is the best', 'the best month']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# without using word tokenizer get the charakter list\n",
        "\n",
        "from nltk.util import ngrams\n",
        "\n",
        "text=\"september is the best month\"\n",
        "\n",
        "characters = [x for x in text]\n",
        "#print(characters)\n",
        "\n",
        "ng= ngrams(characters,3)\n",
        "\n",
        "z=[' '.join(y) for y in ng]\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWqNOOkLezzI",
        "outputId": "b349e45b-e52b-4efe-a42f-ed0e15cc6050"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s e p', 'e p t', 'p t e', 't e m', 'e m b', 'm b e', 'b e r', 'e r  ', 'r   i', '  i s', 'i s  ', 's   t', '  t h', 't h e', 'h e  ', 'e   b', '  b e', 'b e s', 'e s t', 's t  ', 't   m', '  m o', 'm o n', 'o n t', 'n t h']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_ngrams(n):\n",
        "  directory=os.getcwd()+'/ngram'\n",
        "\n",
        "  files = os.listdir(directory)\n",
        "  #print(file)\n",
        "\n",
        "  for x in files:\n",
        "    with open(os.getcwd()+'/ngram/'+x,'r')as f:  #open each file\n",
        "            sentence=f.read().lower()#.split()\n",
        "            print(sentence)\n",
        "\n",
        "            characters=[x for x in sentence]\n",
        "            ng=ngrams(characters,n)\n",
        "            z=[' '.join(y) for y in ng]\n",
        "            print(z)\n",
        "            print('\\n')\n"
      ],
      "metadata": {
        "id": "I1tyo3XSg-1u"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ngrams(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgboIBt-jjcS",
        "outputId": "7b50d7a5-a9e6-45a9-915c-2546ec4c76e0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am sam\n",
            "['i', ' ', 'a', 'm', ' ', 's', 'a', 'm']\n",
            "\n",
            "\n",
            "sam i am\n",
            "['s', 'a', 'm', ' ', 'i', ' ', 'a', 'm']\n",
            "\n",
            "\n",
            "i do not like green eggs and ham\n",
            "['i', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 'g', 'r', 'e', 'e', 'n', ' ', 'e', 'g', 'g', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'a', 'm']\n",
            "\n",
            "\n",
            "i do not like them, sam i am\n",
            "['i', ' ', 'd', 'o', ' ', 'n', 'o', 't', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'm', ',', ' ', 's', 'a', 'm', ' ', 'i', ' ', 'a', 'm']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ngrams(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT3gU0gejoBV",
        "outputId": "4f12a328-81c6-4382-ad99-d170c9f19c35"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am sam\n",
            "['i  ', '  a', 'a m', 'm  ', '  s', 's a', 'a m']\n",
            "\n",
            "\n",
            "sam i am\n",
            "['s a', 'a m', 'm  ', '  i', 'i  ', '  a', 'a m']\n",
            "\n",
            "\n",
            "i do not like green eggs and ham\n",
            "['i  ', '  d', 'd o', 'o  ', '  n', 'n o', 'o t', 't  ', '  l', 'l i', 'i k', 'k e', 'e  ', '  g', 'g r', 'r e', 'e e', 'e n', 'n  ', '  e', 'e g', 'g g', 'g s', 's  ', '  a', 'a n', 'n d', 'd  ', '  h', 'h a', 'a m']\n",
            "\n",
            "\n",
            "i do not like them, sam i am\n",
            "['i  ', '  d', 'd o', 'o  ', '  n', 'n o', 'o t', 't  ', '  l', 'l i', 'i k', 'k e', 'e  ', '  t', 't h', 'h e', 'e m', 'm ,', ',  ', '  s', 's a', 'a m', 'm  ', '  i', 'i  ', '  a', 'a m']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ngrams(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F58E3AzIjsBK",
        "outputId": "743e11cf-7632-461e-abbd-0103af7e01e7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am sam\n",
            "['i   a', '  a m', 'a m  ', 'm   s', '  s a', 's a m']\n",
            "\n",
            "\n",
            "sam i am\n",
            "['s a m', 'a m  ', 'm   i', '  i  ', 'i   a', '  a m']\n",
            "\n",
            "\n",
            "i do not like green eggs and ham\n",
            "['i   d', '  d o', 'd o  ', 'o   n', '  n o', 'n o t', 'o t  ', 't   l', '  l i', 'l i k', 'i k e', 'k e  ', 'e   g', '  g r', 'g r e', 'r e e', 'e e n', 'e n  ', 'n   e', '  e g', 'e g g', 'g g s', 'g s  ', 's   a', '  a n', 'a n d', 'n d  ', 'd   h', '  h a', 'h a m']\n",
            "\n",
            "\n",
            "i do not like them, sam i am\n",
            "['i   d', '  d o', 'd o  ', 'o   n', '  n o', 'n o t', 'o t  ', 't   l', '  l i', 'l i k', 'i k e', 'k e  ', 'e   t', '  t h', 't h e', 'h e m', 'e m ,', 'm ,  ', ',   s', '  s a', 's a m', 'a m  ', 'm   i', '  i  ', 'i   a', '  a m']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# difining jacard co efficient\n",
        "\n",
        "# jac = x n y / x u y\n",
        "\n",
        "def jacard(x,y):\n",
        "  numarater=x.intersection(y) #x n y\n",
        "  dinominator=x.union(y) # x u y\n",
        "  return len(numarater)/len(dinominator)\n",
        "\n",
        "doc3=open(os.getcwd()+'/ngram/D3.txt','r')\n",
        "\n",
        "sentence=doc3.read()\n",
        "print(sentence)\n",
        "characters=[x for x in sentence]\n",
        "ng=ngrams(characters,3)\n",
        "\n",
        "x= [' '.join(x) for x in ng]\n",
        "print(x)\n",
        "print('\\n')\n",
        "\n",
        "doc4=open(os.getcwd()+'/ngram/D4.txt','r')\n",
        "sentence=doc4.read()\n",
        "print(sentence)\n",
        "characters=[x for x in sentence]\n",
        "ng=ngrams(characters,3)\n",
        "\n",
        "y=[' '.join(x_ng) for x_ng in ng]\n",
        "print(y)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "jacard(set(x),set(y))\n",
        "\n",
        "\n",
        "# get minimum edit distance\n",
        "\n",
        "from nltk.metrics.distance import edit_distance\n",
        "print(edit_distance(\"python\",\"pythonly\"))  # wadi wn hri adu wn hari  akuru gana enne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fcwUSNWlwlp",
        "outputId": "bcc20ad8-abe5-47a1-a15b-ee415e512012"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not like green eggs and ham\n",
            "['I   d', '  d o', 'd o  ', 'o   n', '  n o', 'n o t', 'o t  ', 't   l', '  l i', 'l i k', 'i k e', 'k e  ', 'e   g', '  g r', 'g r e', 'r e e', 'e e n', 'e n  ', 'n   e', '  e g', 'e g g', 'g g s', 'g s  ', 's   a', '  a n', 'a n d', 'n d  ', 'd   h', '  h a', 'h a m']\n",
            "\n",
            "\n",
            "I do not like them, Sam I am\n",
            "['I   d', '  d o', 'd o  ', 'o   n', '  n o', 'n o t', 'o t  ', 't   l', '  l i', 'l i k', 'i k e', 'k e  ', 'e   t', '  t h', 't h e', 'h e m', 'e m ,', 'm ,  ', ',   S', '  S a', 'S a m', 'a m  ', 'm   I', '  I  ', 'I   a', '  a m']\n",
            "\n",
            "\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sZIy3_It7O5",
        "outputId": "60391329-c06b-43f1-b186-c3bef9b4b347"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory=os.getcwd()+'/ngram'\n",
        "file=os.listdir(directory)\n",
        "#print(file)\n",
        "\n",
        "\n",
        "for x in file:\n",
        "  with open(os.getcwd()+'/ngram/'+x,'r')as f:\n",
        "    words=f.read().lower().split()\n",
        "    #print(words)\n",
        "    tokenized_word=word_tokenize(x)\n",
        "    print(tokenized_word)"
      ],
      "metadata": {
        "id": "uJFX0JpcbqRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}