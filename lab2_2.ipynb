{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRTS1d0haNGH",
        "outputId": "3c2e71de-9cb8-4354-9396-22afaae444ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/IRWA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81lcOwC4ydYH",
        "outputId": "d79e5ea6-487e-448c-84d5-fd1045267d6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "for doc_no in range(1,4):\n",
        "  with open(str(os.getcwd())+'/positional/doc_'+str(doc_no)+'.txt','r') as file:\n",
        "    s=file.read().replace('\\n','')[1:]\n",
        "    #print(s)\n",
        "\n",
        "    s=re.sub(\"That's\",\"That is\",s)\n",
        "    words=word_tokenize(str(s).lower())\n",
        "    #print(words)\n",
        "\n",
        "    stop_words=stopwords.words('english')\n",
        "    new_sentence=[word for word in words if word not in stop_words]\n",
        "\n",
        "    stemmer=PorterStemmer()\n",
        "    stemmed_word=[]\n",
        "    for i in new_sentence:\n",
        "      stemmed_word.append(stemmer.stem(i))\n",
        "    #print(stemmed_word)\n",
        "    #print(len(stemmed_word))\n",
        "\n",
        "\n",
        "    temp_dict = dict()\n",
        "    dictionary=dict()\n",
        "    a=0\n",
        "    for x in stemmed_word:\n",
        "      key = x\n",
        "      temp_dict.setdefault(key,[])\n",
        "      temp_dict[key].append(a)\n",
        "      a +=1\n",
        "    #print(temp_dict)\n",
        "    for x in temp_dict:\n",
        "       #print(x)\n",
        "       if dictionary.get(x):\n",
        "          dictionary[x][doc_no] =temp_dict.get(x)\n",
        "       else:\n",
        "        key=x\n",
        "        dictionary.setdefault(key,[])\n",
        "        dictionary[key]={}\n",
        "        #print(dictionary[x][doc_no])\n",
        "        dictionary[x][doc_no]=temp_dict.get(x)\n",
        "print(dictionary)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZGMdwbv0rNV",
        "outputId": "21ccaed9-c35b-4d2b-f487-9d66aa60bd41"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'remark': {3: [0]}, 'foreign': {3: [1, 25, 46, 67, 156, 174, 189]}, 'polici': {3: [2, 26, 47, 68, 157, 175, 190]}, 'nation': {3: [3, 14]}, 'press': {3: [4]}, 'club': {3: [5]}, 'washington': {3: [6]}, ',': {3: [7, 11, 34, 37, 74, 77, 95, 119, 128, 152, 155, 170, 173, 186, 199, 212]}, 'thank': {3: [8, 12]}, 'opportun': {3: [9]}, 'speak': {3: [10]}, 'center': {3: [13]}, 'interest': {3: [15, 71, 229]}, 'honor': {3: [16]}, 'invit': {3: [17, 51]}, '.': {3: [18, 40, 48, 57, 66, 79, 84, 91, 101, 104, 108, 116, 123, 129, 146, 150, 161, 168, 181, 193, 206, 219, 233, 238]}, 'would': {3: [19]}, 'like': {3: [20]}, 'talk': {3: [21]}, 'today': {3: [22, 60]}, 'develop': {3: [23, 163]}, 'new': {3: [24, 52, 54, 164, 166]}, 'direct': {3: [27, 58]}, 'countri': {3: [28, 227]}, '\\x96': {3: [29]}, 'one': {3: [30, 188]}, 'replac': {3: [31, 183]}, 'random': {3: [32]}, 'purpos': {3: [33]}, 'ideolog': {3: [35]}, 'strategi': {3: [36]}, 'chao': {3: [38, 211]}, 'peac': {3: [39]}, 'time': {3: [41, 50, 120, 167, 171]}, 'shake': {3: [42]}, 'rust': {3: [43]}, 'america': {3: [44, 85]}, \"'s\": {3: [45, 49, 202]}, 'voic': {3: [53]}, 'vision': {3: [55, 165]}, 'fold': {3: [56]}, 'outlin': {3: [59]}, 'also': {3: [61]}, 'return': {3: [62]}, 'us': {3: [63]}, 'timeless': {3: [64]}, 'principl': {3: [65]}, 'alway': {3: [69]}, 'put': {3: [70]}, 'american': {3: [72, 75]}, 'peopl': {3: [73]}, 'secur': {3: [76]}, 'els': {3: [78]}, 'foundat': {3: [80]}, 'everi': {3: [81]}, 'decis': {3: [82]}, 'make': {3: [83, 177, 224]}, 'first': {3: [86, 97]}, 'major': {3: [87]}, 'overrid': {3: [88]}, 'theme': {3: [89]}, 'administr': {3: [90]}, 'chart': {3: [92]}, 'path': {3: [93]}, 'forward': {3: [94]}, 'must': {3: [96]}, 'briefli': {3: [98]}, 'look': {3: [99]}, 'back': {3: [100, 112]}, 'lot': {3: [102]}, 'proud': {3: [103]}, '1940': {3: [105]}, 'save': {3: [106, 117]}, 'world': {3: [107, 118]}, 'greatest': {3: [109]}, 'gener': {3: [110]}, 'beat': {3: [111]}, 'nazi': {3: [113]}, 'japanes': {3: [114]}, 'imperialist': {3: [115]}, 'totalitarian': {3: [121]}, 'commun': {3: [122]}, 'cold': {3: [124, 153]}, 'war': {3: [125, 154]}, 'last': {3: [126]}, 'decad': {3: [127]}, 'democrat': {3: [130]}, 'republican': {3: [131]}, 'work': {3: [132]}, 'togeth': {3: [133]}, 'got': {3: [134]}, 'mr.': {3: [135]}, 'gorbachev': {3: [136]}, 'heed': {3: [137]}, 'word': {3: [138]}, 'presid': {3: [139, 200]}, 'reagan': {3: [140]}, 'said': {3: [141]}, ':': {3: [142]}, '``': {3: [143]}, 'tear': {3: [144]}, 'wall': {3: [145]}, \"''\": {3: [147]}, 'histori': {3: [148]}, 'forget': {3: [149]}, 'unfortun': {3: [151]}, 'veer': {3: [158]}, 'badli': {3: [159]}, 'cours': {3: [160]}, 'fail': {3: [162]}, 'fact': {3: [169]}, 'went': {3: [172, 194]}, 'began': {3: [176, 220]}, 'less': {3: [178, 179]}, 'sens': {3: [180]}, 'logic': {3: [182]}, 'foolish': {3: [184]}, 'arrog': {3: [185]}, 'led': {3: [187]}, 'disast': {3: [191]}, 'anoth': {3: [192]}, 'mistak': {3: [195]}, 'iraq': {3: [196]}, 'egypt': {3: [197]}, 'libya': {3: [198]}, 'obama': {3: [201]}, 'line': {3: [203]}, 'sand': {3: [204]}, 'syria': {3: [205]}, 'action': {3: [207]}, 'help': {3: [208]}, 'throw': {3: [209]}, 'region': {3: [210]}, 'gave': {3: [213]}, 'isi': {3: [214]}, 'space': {3: [215]}, 'need': {3: [216]}, 'grow': {3: [217]}, 'prosper': {3: [218]}, 'danger': {3: [221]}, 'idea': {3: [222]}, 'could': {3: [223]}, 'western': {3: [225, 231]}, 'democraci': {3: [226, 232]}, 'experi': {3: [228]}, 'becom': {3: [230]}, 'tore': {3: [234]}, 'institut': {3: [235]}, 'surpris': {3: [236]}, 'unleash': {3: [237]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ziBoXCWfvWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wI13YmM4wPE",
        "outputId": "5dd83d1a-ce83-4f23-a316-b1713f891b00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jot169h3wSQ",
        "outputId": "eefc785f-d899-4a83-a908-5d7a29fbd6ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}